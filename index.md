---
layout: default
title: "Jessica â€“ Robotics & HRI"
---

<!-- HERO SECTION -->
<div align="center">
  <h1>Hi, I'm Jessica ğŸ‘‹</h1>
  <p>
    <strong>MSc Robotics & Humanâ€“Robot Interaction</strong><br>
    Focused on embodied interaction, bio-inspired robots, and VR/AR interfaces.
  </p>

  <p>
    <a href="https://github.com/jess-dichakdjian" target="_blank">GitHub</a> Â·
    <a href="https://www.linkedin.com/in/YOUR_LINKEDIN/" target="_blank">LinkedIn</a> Â·
    <a href="assets/CV_Chant.pdf" target="_blank">Download CV</a>
  </p>
</div>

---

## ğŸ¦¾ Featured Robotics & HRI Projects

<!-- PROJECT 1 -->
### ğŸ¦‘ Cuttlefish-Inspired Swimming Robot

<img src="assets/img/cuttlefish.png" alt="Cuttlefish robot simulation" width="100%">

**Goal:** Design and analyze a 9-link bio-inspired swimmer with undulatory motion.

- Built kinematic model of a 30 cm, 9-link soft body with variable amplitude.
- Estimated Reynolds number (~5Ã—10<sup>4</sup>) and studied thrust generation.
- Tools: MATLAB / Python, basic CFD assumptions, robotics kinematics.

ğŸ“ [View code / report on GitHub](https://github.com/YOUR_USERNAME/Cuttlefish_Robot_Simulation)

---

<!-- PROJECT 2 -->
### ğŸ§  VRâ€“Based Humanâ€“Robot Interaction Experiment

<img src="assets/img/vr_hri.png" alt="VR HRI experiment" width="100%">

**Goal:** Study how humans interact with a robot in virtual reality.

- Implemented a VR scenario using **Unity** + **Meta Quest** to test HRI tasks.
- Designed simple interaction tasks (reach, handover, pointing).
- Collected basic user feedback on comfort, intuitiveness, and timing.

- Tools: Unity, C#, Meta Quest, basic UX evaluation.

ğŸ“ [View project on GitHub](https://github.com/YOUR_USERNAME/VR_HRI_Experiment)

---

<!-- PROJECT 3 -->
### ğŸ¤– Gripper Control with Omron TM Flow

<img src="assets/img/gripper_tmflow.png" alt="Omron TM gripper project" width="100%">

**Goal:** Develop simple pick-and-place behaviors with an industrial cobot.

- Programmed an Omron TM robot using TMFlow block programming.
- Implemented safe approach, grasp, and release behaviours.
- Integrated basic perception or fixed jigs for repeatable picking.

- Tools: Omron TMFlow, industrial robot programming.

ğŸ“ [View project on GitHub](https://github.com/YOUR_USERNAME/Gripper_Omron_TMFlow)

---

<!-- PROJECT 4 -->
### âœ‹ Gesture Recognition for Social HRI

<img src="assets/img/gesture_recognition.png" alt="Gesture recognition project" width="100%">

**Goal:** Recognize human gestures for more natural social interaction.

- Implemented a basic pipeline for detecting and classifying gestures.
- Used classical computer vision / or pre-trained pose models (e.g. MediaPipe / OpenPose).
- Evaluated accuracy on a small dataset of gestures.

- Tools: Python, OpenCV, Machine Learning basics.

ğŸ“ [View project on GitHub](https://github.com/YOUR_USERNAME/Gesture_HRI)

---

## ğŸ“š Coursework & Skills

**Relevant Coursework:**

- Humanâ€“Robot Interaction Â· Robotics Â· Control Â· Machine Learning
- Computer Vision Â· VR/AR Interfaces Â· Mechatronics (depending on your actual courses)

**Technical Skills:**

- **Robotics:** ROS / ROS2, Omron TMFlow, kinematics, basic control
- **Programming:** Python, C++, MATLAB, C#
- **Tools:** Unity, Meta Quest, Git, Linux
- **Other:** LaTeX, data analysis, basic UX research

---

## ğŸ‘¤ About Me

I am a Master's student in Robotics with a strong interest in **Humanâ€“Robot Interaction (HRI)**, especially how humans perceive and interact with robots in **embodied** and **immersive** settings (VR/AR).

Right now, I am looking for:

- ğŸ’¡ MSc thesis opportunities in **HRI / Robotics / VR for robotics**  
- ğŸ”¬ Junior research or engineering roles in labs/companies working on HRI, teleoperation, or social robots.

If my profile matches what you're working on, Iâ€™d love to talk!

---

## ğŸ“¬ Contact

- ğŸ“§ Email: YOUR_EMAIL  
- ğŸ”— LinkedIn: [YOUR_LINKEDIN](https://www.linkedin.com/in/YOUR_LINKEDIN/)  
- ğŸ§‘â€ğŸ’» GitHub: [YOUR_USERNAME](https://github.com/jessica-dichakdjian)
